{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**LangChain**\n"
   ],
   "metadata": {
    "id": "hWTEQor1zbaF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uMBEVFbey8qi",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "713e2b04-8883-4736-d4bb-f6f969acfea9"
   },
   "outputs": [],
   "source": [
    "#Установим необходимые библиотеки:\n",
    "!pip install -qU langchain\n",
    "!pip install -qU langchain-openai\n",
    "!pip install -qU langchain-anthropic\n",
    "!pip install -qU langchain-community\n",
    "!pip install -qU wikipedia\n",
    "\n",
    "# или !pip install -qU langchain langchain-openai wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://platform.openai.com/account/api-keys\n",
    "\n",
    "https://smith.langchain.com/\n",
    "\n",
    "https://www.youtube.com/watch?v=VOwI5RsPyzc - Как использовать прокси в браузере"
   ],
   "metadata": {
    "id": "UzFkPBht1N9l"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# опционально:\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = userdata.get(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "yOOxhmlg076O"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "print(\"OPENAI_API_KEY:\", bool(os.getenv(\"OPENAI_API_KEY\")))\n",
    "print(\"LANGCHAIN_API_KEY:\", bool(os.getenv(\"LANGCHAIN_API_KEY\")))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3sASarYc9IgF",
    "outputId": "1505f982-63da-49b2-aa24-9a277b4d3e86"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain_openai import ChatOpenAI\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = ChatOpenAI(\n",
    "\tmodel=\"gpt-4o-mini\",\n",
    "\ttemperature=0.7,\n",
    "\tmax_tokens=1000\n",
    "\t)"
   ],
   "metadata": {
    "id": "bupVKdV5Fa5Y"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "SystemMessage(content=\"Translate the following from English into Italian\"),\n",
    "HumanMessage(content=\"hi!\"),\n",
    "\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ],
   "metadata": {
    "id": "_WhFAdB2HKfb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8b3f2fc1-cffe-488b-893f-8411bce1150d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Используем конструкцию, чтобы получить исключительно ответ от языковой модели."
   ],
   "metadata": {
    "id": "CCLplRiH-SIZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "result = model.invoke(messages)\n",
    "parser.invoke(result)"
   ],
   "metadata": {
    "id": "V75JKhn8IPIK",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "4afac45e-741b-4abb-eb2d-17e714d6c6fe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "chain = model | parser\n",
    "chain.invoke(messages)"
   ],
   "metadata": {
    "id": "Jxzz5hWEIklK",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "a6444db0-51f4-4a15-92d0-a56c944dc1a8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Проверим LangSmith!"
   ],
   "metadata": {
    "id": "lFLR_cV3KCps"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#получим стоимость запроса\n",
    "from langchain_community.callbacks.manager import get_openai_callback\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = chain.invoke(messages)\n",
    "    print(cb)"
   ],
   "metadata": {
    "id": "F80r1WdOIkW9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0baa0438-7376-4360-f24e-d909f5765a22"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#проверим другую модель\n",
    "model4 = ChatOpenAI(model=\"gpt-4o\")\n",
    "chain4 = model4 | parser\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = chain4.invoke(messages)\n",
    "    print(cb)"
   ],
   "metadata": {
    "id": "3EInDdyVMPoE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "38fe28b7-d378-44ef-fee2-43c349414edd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Total Cost (USD): {cb.total_cost}$\")"
   ],
   "metadata": {
    "id": "Cy_O5MNJO_K8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "299615f6-a580-4ad9-8ebd-540258aeafd6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Используем шаблон промпта\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following into {language}:\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ],
   "metadata": {
    "id": "CYmyhaUXNF3i"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "result = prompt_template.invoke({\"language\": \"italian\", \"text\": \"hi\"})\n",
    "\n",
    "result"
   ],
   "metadata": {
    "id": "DwkMxAq3J3VS",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "636b1c7d-4a5b-48c4-cdd0-c221e9047a53"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#доступ к сообщениям\n",
    "result.to_messages()#[0]"
   ],
   "metadata": {
    "id": "vlxqotaojHWd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8189cd42-2d89-4529-92ae-4b3971f127ba"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "result.to_messages()[0]"
   ],
   "metadata": {
    "id": "XhFe2oCANF0y",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "99db07b3-ddc0-4421-bb78-2da5ffb308d7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#добавляем шаблон\n",
    "chain = prompt_template | model | parser"
   ],
   "metadata": {
    "id": "5aieAglgNFyI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "chain.invoke({\"language\": \"italian\", \"text\": \"hi\"})"
   ],
   "metadata": {
    "id": "DMkl79u2NFvK",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "fdbe3212-35bb-4418-94a5-dca64495f55a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Пример использования\n",
    "system_template = \"Ты - полезный бот массовик затейник. Ты знаешь много способов провести интересно время. Тебя зовут {name}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template),\n",
    "    (\"user\", \"Меня зовут Михаил. Я люблю карточные игры, особенно покер. Хочу научиться играть в преферанс. \\\n",
    "        Не люблю гулять на свежем воздухе\"),\n",
    "\n",
    "        (\"user\", \"{user_input}\")]\n",
    "\n",
    ")\n",
    "\n",
    "result = prompt_template.invoke({\"name\": \"Бодрый друг\", \"user_input\": \"На улице солнечно. Чем посоветуешь заняться?\"})\n",
    "\n",
    "chain = prompt_template | model | parser\n",
    "data = {\"name\": \"Бодрый друг\", \"user_input\": \"На улице солнечно. Чем посоветуешь заняться?\"}\n",
    "chain.invoke(data)"
   ],
   "metadata": {
    "id": "gftkPdKHNFp9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "outputId": "089768e3-1383-43cb-92bd-834d91d2f625"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#ответ в режиме стрима\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7,\n",
    "    )\n",
    "for chunk in chat.stream(\"Напиши тезисы про важность промпт-инжиниринга\"):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ],
   "metadata": {
    "id": "BjIgaqKMD0It",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "816a9068-949a-42af-9632-29aa230fb2b6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    " LangChain. Взаимодействие с языковыми моделями: Часть 2"
   ],
   "metadata": {
    "id": "hbjSbI8jjXFu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# Pydantic-модель\n",
    "class Person(BaseModel):\n",
    "    name: str = Field(description=\"Полное имя человека\")\n",
    "    age: int = Field(description=\"Возраст человека\")\n",
    "    hobbies: List[str] = Field(description=\"Список хобби\")\n",
    "\n",
    "# Парсер\n",
    "parser = PydanticOutputParser(pydantic_object=Person)\n",
    "\n",
    "# Шаблон промпта\n",
    "prompt = PromptTemplate(\n",
    "    template=(\n",
    "        \"Сгенерируй информацию о человеке.\\n\"\n",
    "        \"{format_instructions}\\n\"\n",
    "        \"Описание: {input}\"\n",
    "    ),\n",
    "    input_variables=[\"input\"],\n",
    "    partial_variables={\n",
    "        \"format_instructions\": parser.get_format_instructions()\n",
    "    },\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "result = chain.invoke({\"input\": \"Молодая женщина, увлекается бегом и йогой\"})\n",
    "print(result)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "380VTwg1B4cz",
    "outputId": "2aad1465-9a70-4120-b460-2261a909a016"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}